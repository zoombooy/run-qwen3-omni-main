/**
 * MultiModalService - å¤šæ¨¡æ€äº¤äº’æœåŠ¡
 * æ•´åˆå½•éŸ³ã€æˆªå›¾å’ŒVADæ£€æµ‹ï¼Œå®ç°å®Œæ•´çš„è¯­éŸ³äº¤äº’æµç¨‹
 * åŸºäºexampleä¸­çš„æˆç†Ÿæ¨¡å—é‡æ„ï¼Œæä¾›æ›´å¥½çš„æ€§èƒ½å’Œç¨³å®šæ€§
 * 
 * è¯­éŸ³äº¤äº’æ§åˆ¶æµç¨‹ï¼š
 * - é€šè¿‡VADæ£€æµ‹è¯­éŸ³å¼€å§‹ä¸ç»“æŸ
 * - å‘é€æ—¶é™„å¸¦æœ€åä¸€å¼ æˆªå›¾
 * - AIå›å¤æœŸé—´åœæ­¢å½•éŸ³ï¼Œç•Œé¢æ˜¾ç¤ºç­‰å¾…çŠ¶æ€
 * - VADå¤±æ•ˆç›´è‡³å›å¤ç»“æŸ
 */

import { EventEmitter } from 'eventemitter3'
import { Agent, type AgentConfig } from '@/modules/agent'
import { AudioRecorder } from '@/lib/audio-recorder'
import { AudioStreamer } from '@/lib/audio-streamer'
import { useScreenCapture, type UseScreenCaptureResult } from '@/composables/useScreenCapture'
import { ModernVadDetector, type ModernVadConfig } from '@/lib/modern-vad-detector'
import { audioContext } from '@/lib/utils'
import { testTool } from '@/modules/llm/LLMExample'
import { canvasTools } from '@/modules/tools/canvasTools'

// ===== ç±»å‹å®šä¹‰ =====
export interface MultiModalServiceConfig {
  agentConfig: AgentConfig
  vadConfig?: Partial<ModernVadConfig>
  screenshotConfig?: {
    captureInterval?: number
    maxScreenshots?: number
    includeSystemAudio?: boolean
    showPreview?: boolean
    imageQuality?: number
  }
  audioConfig?: {
    sampleRate?: number
    quality?: number
    volume?: number
  }
  conversationConfig?: {
    sendHistoryImages?: boolean
    sendHistoryAudio?: boolean  // æ–°å¢ï¼šæ˜¯å¦å‘é€å†å²éŸ³é¢‘
  }
}

export enum ServiceState {
  IDLE = 'idle',
  INITIALIZING = 'initializing', 
  READY = 'ready',
  LISTENING = 'listening',
  VOICE_ACTIVE = 'voice_active',
  PROCESSING = 'processing',
  ERROR = 'error'
}

export interface ServiceStatus {
  state: ServiceState
  isInitialized: boolean
  isListening: boolean
  isProcessing: boolean
  isCapturing: boolean
  isVoiceActive: boolean
}

interface Screenshot {
  data: string
  timestamp: number
}

export class MultiModalService extends EventEmitter {
  // çŠ¶æ€ç®¡ç†
  private currentState: ServiceState = ServiceState.IDLE
  private status: ServiceStatus
  
  // æ ¸å¿ƒç»„ä»¶ - ä½¿ç”¨ç°ä»£åŒ–å®ç°
  private agent: Agent
  private audioRecorder: AudioRecorder
  private audioStreamer: AudioStreamer | null = null
  private audioContext: AudioContext | null = null
  private vadDetector: ModernVadDetector
  private detachVadListeners: (() => void) | null = null
  private screenCapture: UseScreenCaptureResult
  
  private config: MultiModalServiceConfig
  private toolsEnabled = true
  
  // éŸ³é¢‘å¤„ç†ç›¸å…³
  private audioChunks: string[] = [] // å­˜å‚¨base64éŸ³é¢‘æ•°æ®
  private screenshots: Screenshot[] = []
  private isRecordingVoice: boolean = false
  private hasRecordedVoiceChunk: boolean = false
  private listeningStartedAt: number | null = null
  private captureTimer: number | null = null

  constructor(config: MultiModalServiceConfig) {
    super()

    this.config = config
    this.status = {
      state: ServiceState.IDLE,
      isInitialized: false,
      isListening: false,
      isProcessing: false,
      isCapturing: false,
      isVoiceActive: false
    }

    // åˆå¹¶conversationConfigåˆ°agentConfigä¸­
    const mergedAgentConfig = {
      ...config.agentConfig,
      sendHistoryImages: config.conversationConfig?.sendHistoryImages ?? false,
      sendHistoryAudio: config.conversationConfig?.sendHistoryAudio ?? false  // æ”¯æŒå†å²éŸ³é¢‘é…ç½®
    }

    // åˆå§‹åŒ–å„ä¸ªç®¡ç†å™¨
    this.agent = new Agent(mergedAgentConfig)
    this.agent.setToolsEnabled(this.toolsEnabled)

    // æ³¨å†Œæµ‹è¯•å·¥å…·ä¸ç”»å¸ƒæ§åˆ¶å·¥å…·
    this.agent.registerTools([testTool])
    this.agent.registerTools(canvasTools)

    // åˆå§‹åŒ–éŸ³é¢‘å½•åˆ¶å™¨
    const sampleRate = config.audioConfig?.sampleRate ?? 16000
    this.audioRecorder = new AudioRecorder(sampleRate)

    // åˆå§‹åŒ–VADæ£€æµ‹å™¨
    this.vadDetector = new ModernVadDetector({
      threshold: config.vadConfig?.threshold ?? 5,
      silenceDuration: config.vadConfig?.silenceDuration ?? 800,
      onVoiceStart: () => this.onVoiceStart(),
      onVoiceStop: () => this.onVoiceStop()
    })

    // åˆå§‹åŒ–å±å¹•æ•è·
    this.screenCapture = useScreenCapture()

    // åº”ç”¨é»˜è®¤æˆªå›¾é…ç½®
    if (!this.config.screenshotConfig) {
      this.config.screenshotConfig = {}
    }
    this.config.screenshotConfig.captureInterval = this.config.screenshotConfig.captureInterval ?? 2000
    this.config.screenshotConfig.maxScreenshots = this.config.screenshotConfig.maxScreenshots ?? 1
    this.config.screenshotConfig.showPreview = this.config.screenshotConfig.showPreview ?? true
    this.config.screenshotConfig.imageQuality = this.config.screenshotConfig.imageQuality ?? 0.8

    this.setupEventListeners()
  }

  // åˆå§‹åŒ–æœåŠ¡
  async initialize(): Promise<void> {
    try {
      this.currentState = ServiceState.INITIALIZING
      this.emit('stateChanged', this.currentState)

      // åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡
      this.audioContext = await audioContext({ 
        sampleRate: this.config.audioConfig?.sampleRate ?? 24000 
      })
      
      // åˆå§‹åŒ–VADæ£€æµ‹å™¨
      this.vadDetector.initialize((volume) => {
        this.vadDetector.processVolume(volume)
      })

      this.currentState = ServiceState.READY
      this.status.isInitialized = true
      this.emit('initialized')
      this.emit('stateChanged', this.currentState)
      
      console.log('âœ… MultiModalService åˆå§‹åŒ–æˆåŠŸ')
    } catch (error) {
      this.currentState = ServiceState.ERROR
      this.emit('stateChanged', this.currentState)
      console.error('âŒ MultiModalService åˆå§‹åŒ–å¤±è´¥:', error)
      throw error
    }
  }

  // å¼€å§‹ç›‘å¬ï¼ˆä»…å½•éŸ³ï¼‰
  async startListening(): Promise<void> {
    if (!this.status.isInitialized) {
      throw new Error('Service not initialized')
    }

    if (this.status.isListening) {
      console.warn('Already listening')
      return
    }

    try {
      this.currentState = ServiceState.LISTENING

      // å¯åŠ¨éŸ³é¢‘å½•åˆ¶
      await this.audioRecorder.start()
      this.status.isListening = true
      this.listeningStartedAt = Date.now()

      // å¯åŠ¨VADæ£€æµ‹
      this.vadDetector.startDetection()

      this.emit('listeningStarted')
      this.emit('stateChanged', this.currentState)

      console.log('ğŸ™ï¸ è¯­éŸ³ç›‘å¬å·²å¯åŠ¨')
    } catch (error) {
      // æ¸…ç†å·²å¯åŠ¨çš„èµ„æº
      if (this.audioRecorder.isRecording()) {
        await this.audioRecorder.stop()
      }

      this.currentState = ServiceState.ERROR
      this.emit('stateChanged', this.currentState)
      console.error('âŒ å¯åŠ¨ç›‘å¬å¤±è´¥:', error)
      throw error
    }
  }

  // å¼€å§‹å±å¹•æ•è·
  async startScreenCapture(): Promise<void> {
    if (this.status.isCapturing) {
      console.warn('Already capturing screen')
      return
    }

    try {
      await this.screenCapture.startScreenCapture()

      // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿Vueå“åº”æ€§æ›´æ–°å®Œæˆ
      await new Promise(resolve => setTimeout(resolve, 50))

      console.log('ğŸ–¼ï¸ æ£€æŸ¥æµçŠ¶æ€:', {
        isStreaming: this.screenCapture.isStreaming.value,
        getStreamingStatus: this.screenCapture.getStreamingStatus(),
        stream: !!this.screenCapture.stream.value,
        streamActive: this.screenCapture.stream.value?.active
      })

      // ä½¿ç”¨åŒæ­¥æ£€æŸ¥æ–¹æ³•éªŒè¯å±å¹•æ•è·æ˜¯å¦çœŸæ­£å¯åŠ¨
      if (this.screenCapture.getStreamingStatus()) {
        this.status.isCapturing = true
        this.startScreenshotCapture()
        console.log('ğŸ–¼ï¸ å±å¹•æ•è·å·²å¯åŠ¨')
        this.emit('screenCaptureStarted')
      } else {
        throw new Error('å±å¹•æ•è·å¯åŠ¨å¤±è´¥ï¼šæµæœªæ¿€æ´»')
      }
    } catch (error) {
      console.error('ğŸ–¼ï¸ å±å¹•æ•è·å¯åŠ¨å¼‚å¸¸:', error)
      if (this.isScreenshotPermissionDenied(error)) {
        console.warn('ğŸ–¼ï¸ å±å¹•æ•è·æƒé™è¢«æ‹’ç»')
        this.emit('captureDisabled', { reason: 'permission-denied' })
        throw new Error('å±å¹•æ•è·æƒé™è¢«æ‹’ç»')
      } else {
        console.error('ğŸ–¼ï¸ å±å¹•æ•è·å¯åŠ¨å¤±è´¥:', error)
        throw error
      }
    }
  }

  // åœæ­¢å±å¹•æ•è·
  async stopScreenCapture(): Promise<void> {
    if (!this.status.isCapturing) {
      return
    }

    console.log('ğŸ›‘ æ­£åœ¨åœæ­¢å±å¹•æ•è·...')

    // åœæ­¢å±å¹•æ•è·
    if (this.screenCapture.isStreaming.value) {
      this.screenCapture.stopScreenCapture()
    }

    // åœæ­¢å®šæ—¶æˆªå›¾
    if (this.captureTimer) {
      clearInterval(this.captureTimer)
      this.captureTimer = null
    }

    // é‡ç½®çŠ¶æ€
    this.status.isCapturing = false
    this.screenshots = []

    this.emit('screenCaptureStopped')
    console.log('ğŸ›‘ å±å¹•æ•è·å·²åœæ­¢')
  }

  // åœæ­¢ç›‘å¬
  async stopListening(): Promise<void> {
    if (!this.status.isListening) {
      return
    }

    console.log('ğŸ›‘ æ­£åœ¨åœæ­¢ç›‘å¬...')

    // åœæ­¢éŸ³é¢‘å½•åˆ¶
    if (this.audioRecorder.isRecording()) {
      await this.audioRecorder.stop()
    }

    // åœæ­¢VADæ£€æµ‹
    this.vadDetector.stopDetection()

    // é‡ç½®çŠ¶æ€
    this.status.isListening = false
    this.status.isVoiceActive = false
    this.isRecordingVoice = false
    this.hasRecordedVoiceChunk = false
    this.audioChunks = []
    this.listeningStartedAt = null

    this.currentState = ServiceState.READY
    this.emit('listeningStopped')
    this.emit('stateChanged', this.currentState)
    console.log('ğŸ›‘ ç›‘å¬å·²åœæ­¢')
  }

  // æ‰‹åŠ¨å¼€å§‹è¯­éŸ³æ•è·ï¼ˆæŒ‰ä½è¯´è¯æ¨¡å¼ï¼‰
  beginManualVoiceCapture(): void {
    console.log('ğŸ¤ æ‰‹åŠ¨å¼€å§‹è¯­éŸ³æ•è· - æŒ‰ä½è¯´è¯æ¨¡å¼')
    
    if (!this.status.isListening) {
      console.warn('æœåŠ¡æœªåœ¨ç›‘å¬çŠ¶æ€ï¼Œæ— æ³•å¼€å§‹è¯­éŸ³æ•è·')
      return
    }

    if (this.status.isProcessing) {
      console.log('AIæ­£åœ¨å¤„ç†ä¸­ï¼Œå¿½ç•¥è¯­éŸ³æ•è·è¯·æ±‚')
      return
    }

    this.startVoiceCapture()
  }

  // æ‰‹åŠ¨ç»“æŸè¯­éŸ³æ•è·
  async endManualVoiceCapture(): Promise<void> {
    console.log('ğŸ¤ æ‰‹åŠ¨ç»“æŸè¯­éŸ³æ•è·')
    
    if (!this.isRecordingVoice) {
      console.warn('å½“å‰æœªåœ¨å½•åˆ¶è¯­éŸ³')
      return
    }

    await this.finalizeVoiceCapture()
  }

  // å¼€å§‹è¯­éŸ³æ•è·
  private startVoiceCapture(): void {
    console.log('ğŸ¤ startVoiceCapture - çŠ¶æ€æ£€æŸ¥', {
      isListening: this.status.isListening,
      isProcessing: this.status.isProcessing,
      isRecordingVoice: this.isRecordingVoice
    })

    if (!this.status.isListening || this.status.isProcessing) {
      console.log('ğŸ¤ è·³è¿‡è¯­éŸ³æ•è· - æœåŠ¡çŠ¶æ€ä¸å…è®¸')
      return
    }

    if (this.isRecordingVoice) {
      console.log('ğŸ¤ å·²åœ¨å½•åˆ¶è¯­éŸ³ï¼Œè·³è¿‡é‡å¤å¯åŠ¨')
      return
    }

    console.log('ğŸ¤ è¯­éŸ³æ£€æµ‹åˆ°ï¼Œå¼€å§‹å½•åˆ¶')
    this.currentState = ServiceState.VOICE_ACTIVE
    this.status.isVoiceActive = true
    this.isRecordingVoice = true
    this.audioChunks = []
    this.hasRecordedVoiceChunk = false

    this.emit('voiceDetectionStarted')
    this.emit('voiceInputStarted')
    this.emit('stateChanged', this.currentState)
  }

  // ç»“æŸè¯­éŸ³æ•è·å¹¶å¤„ç†
  private async finalizeVoiceCapture(): Promise<void> {
    console.log('ğŸ¤ finalizeVoiceCapture - çŠ¶æ€æ£€æŸ¥', {
      isRecordingVoice: this.isRecordingVoice,
      isProcessing: this.status.isProcessing,
      audioChunks: this.audioChunks.length,
      hasRecordedVoiceChunk: this.hasRecordedVoiceChunk
    })

    if (!this.isRecordingVoice || this.status.isProcessing) {
      console.log('ğŸ¤ è·³è¿‡è¯­éŸ³ç»“æŸå¤„ç†')
      return
    }

    console.log('ğŸ¤ è¯­éŸ³ç»“æŸï¼Œå¼€å§‹å¤„ç†æ¶ˆæ¯')
    this.status.isVoiceActive = false
    this.isRecordingVoice = false

    // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ä»¥è·å–æœ€åçš„éŸ³é¢‘å—
    await new Promise(resolve => setTimeout(resolve, 100))

    // è·å–æœ€æ–°æˆªå›¾
    const maxScreenshots = this.config.screenshotConfig?.maxScreenshots ?? 1
    const screenshots = this.getLatestScreenshots(maxScreenshots)
    const imageBase64List = screenshots.map(s => s.data)
    const audioBase64 = this.combineAudioChunks()
    
    console.log('ğŸ“‹ å‡†å¤‡å‘é€æ•°æ®', {
      screenshots: screenshots.length,
      imageBase64List: imageBase64List.length,
      audioBase64Length: audioBase64.length,
      hasAudio: audioBase64.length > 0,
      hasImages: imageBase64List.length > 0
    })

    this.emit('voiceDetectionStopped')

    // æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„éŸ³é¢‘æ•°æ®
    const MIN_AUDIO_CHUNKS = 3
    const hasUsableAudio = this.hasRecordedVoiceChunk && this.audioChunks.length >= MIN_AUDIO_CHUNKS && audioBase64.length > 0

    if (!hasUsableAudio) {
      console.warn('è¯­éŸ³åœæ­¢ä½†éŸ³é¢‘æ•°æ®å¤ªçŸ­ï¼Œè·³è¿‡å‘é€', {
        hasRecordedVoiceChunk: this.hasRecordedVoiceChunk,
        chunkCount: this.audioChunks.length,
        audioBase64Length: audioBase64.length
      })
      this.audioChunks = []
      this.hasRecordedVoiceChunk = false
      this.currentState = ServiceState.LISTENING
      this.emit('stateChanged', this.currentState)
      return
    }

    this.emit('voiceInputCaptured', {
      audioChunks: this.audioChunks.length,
      screenshotCount: screenshots.length,
      audioBase64Length: audioBase64.length,
      images: imageBase64List // æ·»åŠ å›¾ç‰‡æ•°æ®
    })

    await this.processAgentRequest({
      text: '',
      images: imageBase64List,
      audio: audioBase64
    })

    this.audioChunks = []
    this.hasRecordedVoiceChunk = false
  }

  // VADäº‹ä»¶å¤„ç†
  private onVoiceStart(): void {
    const now = Date.now()
    if (this.listeningStartedAt && now - this.listeningStartedAt < 800) {
      console.log('è¯­éŸ³å¼€å§‹è¢«å¿½ç•¥ - åœ¨å®½é™æœŸå†…')
      return
    }

    this.startVoiceCapture()
  }

  private async onVoiceStop(): Promise<void> {
    await this.finalizeVoiceCapture()
  }

  // å¤„ç†Agentè¯·æ±‚
  private async processAgentRequest(payload: { text?: string; images?: string[]; audio?: string }): Promise<void> {
    const hasText = payload.text && payload.text.trim().length > 0
    const hasImages = Boolean(payload.images && payload.images.length > 0)
    const hasAudio = Boolean(payload.audio && payload.audio.length > 0)

    console.log('ğŸš€ å¤„ç†Agentè¯·æ±‚', {
      hasText,
      hasImages,
      hasAudio,
      textLength: payload.text?.length || 0,
      imagesCount: payload.images?.length || 0,
      audioLength: payload.audio?.length || 0
    })

    if (!hasText && !hasImages && !hasAudio) {
      console.warn('æ²¡æœ‰å†…å®¹æä¾›ç»™Agentè¯·æ±‚')
      this.currentState = ServiceState.LISTENING
      this.emit('stateChanged', this.currentState)
      return
    }

    if (this.status.isProcessing) {
      console.warn('æœåŠ¡æ­£åœ¨å¤„ç†è¯·æ±‚ï¼Œå¿½ç•¥æ–°çš„è´Ÿè½½')
      return
    }

    try {
      this.status.isProcessing = true
      this.currentState = ServiceState.PROCESSING
      this.emit('processingStarted')
      this.emit('stateChanged', this.currentState)

      // æš‚åœç›‘å¬ï¼ˆAIå›å¤æœŸé—´åœæ­¢å½•éŸ³ï¼ŒVADå¤±æ•ˆï¼‰
      if (this.status.isListening) {
        this.pauseListening()
      }

      console.log('ğŸ“¤ å‘é€åˆ°Agentçš„æ•°æ®:', {
        hasText,
        hasImages,
        hasAudio,
        payload: {
          text: payload.text,
          images: payload.images ? `${payload.images.length} images` : 'no images',
          audio: payload.audio ? `${payload.audio.length} chars` : 'no audio'
        }
      })

      await this.agent.sendMultiModalMessage(payload)
    } catch (error) {
      console.error('âŒ å¤„ç†Agentè¯·æ±‚å¤±è´¥:', error)
      this.emit('error', error)
      if (this.status.isListening) {
        this.resumeListening()
      }
      this.status.isProcessing = false
      this.currentState = ServiceState.LISTENING
      this.emit('stateChanged', this.currentState)
    }
  }

  // æš‚åœ/æ¢å¤ç›‘å¬ï¼ˆæŒ‰ç…§è¯­éŸ³äº¤äº’æ§åˆ¶æµç¨‹è§„èŒƒï¼‰
  private pauseListening(): void {
    console.log('â¸ï¸ æš‚åœè¯­éŸ³ç›‘å¬ - AIå›å¤æœŸé—´')
    this.vadDetector.stopDetection()
    this.emit('listeningPaused')
  }

  private resumeListening(): void {
    console.log('â–¶ï¸ æ¢å¤è¯­éŸ³ç›‘å¬')
    if (this.status.isListening) {
      // å®Œå…¨é‡ç½®VADæ£€æµ‹å™¨çŠ¶æ€
      this.vadDetector.dispose()

      // é‡æ–°åˆ›å»ºVADæ£€æµ‹å™¨ï¼Œç¡®ä¿çŠ¶æ€å®Œå…¨é‡ç½®
      this.vadDetector = new ModernVadDetector({
        threshold: this.config.vadConfig?.threshold ?? 5,
        silenceDuration: this.config.vadConfig?.silenceDuration ?? 800,
        onVoiceStart: () => this.onVoiceStart(),
        onVoiceStop: () => this.onVoiceStop()
      })

      // é‡æ–°åˆå§‹åŒ–å¹¶è¿æ¥éŸ³é¢‘å½•åˆ¶å™¨
      this.vadDetector.initialize((volume) => {
        this.vadDetector.processVolume(volume)
      })

      this.attachVadEventListeners()
      // é‡æ–°è®¾ç½®éŸ³é¢‘å½•åˆ¶å™¨çš„éŸ³é‡äº‹ä»¶ç›‘å¬
      this.setupAudioRecorderVolumeListener()

      // å¯åŠ¨VADæ£€æµ‹
      this.vadDetector.startDetection()

      // é‡ç½®æ—¶é—´å’ŒçŠ¶æ€
      this.listeningStartedAt = Date.now()
      this.status.isVoiceActive = false
      this.isRecordingVoice = false

      this.emit('listeningResumed')
      console.log('â–¶ï¸ VADæ£€æµ‹å™¨å·²å®Œå…¨é‡ç½®å¹¶é‡æ–°å¯åŠ¨')
    }
  }

  // è®¾ç½®äº‹ä»¶ç›‘å¬å™¨
  private setupEventListeners(): void {
    this.setupAudioRecorderEventListeners()
    this.setupAgentEventListeners()
    this.attachVadEventListeners()
  }

  // è®¾ç½®éŸ³é¢‘å½•åˆ¶å™¨äº‹ä»¶ç›‘å¬
  private setupAudioRecorderEventListeners(): void {
    // AudioRecorderäº‹ä»¶
    this.audioRecorder.on('data', (base64Data: string) => {
      if (this.isRecordingVoice && !this.status.isProcessing) {
        this.audioChunks.push(base64Data)
        this.hasRecordedVoiceChunk = true
        
        // è°ƒè¯•æ—¥å¿—
        if (this.audioChunks.length % 10 === 0) {
          console.log('ğŸµ éŸ³é¢‘æ•°æ®å·²æ”¶é›†', {
            chunks: this.audioChunks.length,
            isRecordingVoice: this.isRecordingVoice,
            chunkLength: base64Data.length
          })
        }
      } else {
        // console.log('ğŸµ è·³è¿‡éŸ³é¢‘æ•°æ®', {
        //   isRecordingVoice: this.isRecordingVoice,
        //   isProcessing: this.status.isProcessing,
        //   chunkLength: base64Data.length
        // })
      }
    })

    this.setupAudioRecorderVolumeListener()

    this.audioRecorder.on('stopped', () => {
      console.log('ğŸ™ï¸ å½•éŸ³å™¨å·²åœæ­¢')
    })
  }

  // è®¾ç½®éŸ³é¢‘å½•åˆ¶å™¨éŸ³é‡ç›‘å¬ï¼ˆç‹¬ç«‹æ–¹æ³•ï¼Œç”¨äºé‡ç½®æ—¶é‡æ–°è¿æ¥ï¼‰
  private setupAudioRecorderVolumeListener(): void {
    // ç§»é™¤æ—§çš„éŸ³é‡ç›‘å¬å™¨
    this.audioRecorder.removeAllListeners('volume')

    // æ·»åŠ æ–°çš„éŸ³é‡ç›‘å¬å™¨
    this.audioRecorder.on('volume', (volume: number) => {
      // ä¼ é€’ç»™VADæ£€æµ‹å™¨
      if (this.vadDetector && this.status.isListening) {
        this.vadDetector.processVolume(volume)
      }
      // å‘é€å¯è§†åŒ–æ•°æ®
      this.emit('microphoneVisualization', { volume })
    })
  }

  // è®¾ç½®Agentäº‹ä»¶ç›‘å¬
  private setupAgentEventListeners(): void {

    this.agent.on('responseStarted', () => {
      console.log('ğŸ¤– AIå¼€å§‹å›å¤')
      this.beginStreamingPlayback()
      this.emit('agentResponseStarted')
    })

    this.agent.on('responseChunk', (response) => {
      if (response.audioChunk && this.audioStreamer) {
        try {
          // å°†ArrayBufferè½¬æ¢ä¸ºUint8Array
          const uint8Array = new Uint8Array(response.audioChunk)
          this.audioStreamer.addPCM16(uint8Array)
        } catch (error) {
          console.error('å¤„ç†éŸ³é¢‘å—å¤±è´¥:', error)
        }
      }

      this.emit('agentResponseChunk', response)
    })

    this.agent.on('responseCompleted', (response) => {
      console.log('ğŸ¤– AIå›å¤å®Œæˆ')
      this.finishStreamingPlayback()

      // æ¢å¤ç›‘å¬
      this.resumeListening()
      this.status.isProcessing = false
      this.currentState = ServiceState.LISTENING

      this.emit('agentResponseCompleted', response)
      this.emit('processingCompleted')
      this.emit('stateChanged', this.currentState)
    })

    this.agent.on('responseError', (error) => {
      console.error('Agentå›å¤é”™è¯¯:', error)
      this.finishStreamingPlayback()
      this.resumeListening()
      this.status.isProcessing = false
      this.currentState = ServiceState.LISTENING
      this.emit('error', error)
      this.emit('stateChanged', this.currentState)
    })

    this.agent.on('toolCallStarted', (toolCall) => {
      console.log('ğŸ› ï¸ å·¥å…·è°ƒç”¨å¼€å§‹:', toolCall)
      this.emit('toolCallStarted', toolCall)
    })

    this.agent.on('toolCallCompleted', (payload) => {
      console.log('âœ… å·¥å…·è°ƒç”¨å®Œæˆ:', payload)
      this.emit('toolCallCompleted', payload)
    })

    this.agent.on('toolCallFailed', (payload) => {
      console.log('âŒ å·¥å…·è°ƒç”¨å¤±è´¥:', payload)
      this.emit('toolCallFailed', payload)
    })
  }

  // è®¾ç½®VADäº‹ä»¶ç›‘å¬
  private attachVadEventListeners(): void {
    this.detachVadListeners?.()

    if (!this.vadDetector) {
      return
    }

    const vad = this.vadDetector
    const handleVoiceStart = () => {
      this.emit('voiceStarted')
    }

    const handleVoiceStop = () => {
      this.emit('voiceStopped')
    }

    vad.on('voiceStart', handleVoiceStart)
    vad.on('voiceStop', handleVoiceStop)

    this.detachVadListeners = () => {
      vad.off('voiceStart', handleVoiceStart)
      vad.off('voiceStop', handleVoiceStop)
      this.detachVadListeners = null
    }
  }

  // éŸ³é¢‘æµæ’­æ”¾ç®¡ç†
  private beginStreamingPlayback(): void {
    if (!this.audioContext) {
      console.warn('éŸ³é¢‘ä¸Šä¸‹æ–‡ä¸å¯ç”¨äºæµæ’­æ”¾')
      return
    }

    try {
      const streamer = new AudioStreamer(this.audioContext)
      streamer.onComplete = () => {
        if (this.audioStreamer === streamer) {
          streamer.dispose()
          this.audioStreamer = null
        } else {
          streamer.dispose()
        }
      }

      this.audioStreamer = streamer
      this.audioStreamer.resume()
    } catch (error) {
      console.error('å¯åŠ¨æµæ’­æ”¾å¤±è´¥:', error)
    }
  }

  private finishStreamingPlayback(): void {
    if (this.audioStreamer) {
      this.audioStreamer.complete()
    }
  }

  // å±å¹•æˆªå›¾ç®¡ç†
  private startScreenshotCapture(): void {
    const interval = this.config.screenshotConfig?.captureInterval ?? 2000
    const maxScreenshots = this.config.screenshotConfig?.maxScreenshots ?? 1

    this.captureTimer = window.setInterval(async () => {
      try {
        // ä½¿ç”¨åŒæ­¥æ£€æŸ¥æ–¹æ³•æ£€æŸ¥æµçŠ¶æ€
        if (!this.screenCapture.getStreamingStatus()) {
          console.warn('ğŸ“¸ æˆªå›¾å¤±è´¥ï¼šå±å¹•æµæœªæ¿€æ´»ï¼Œå°è¯•é‡æ–°å¯åŠ¨...')

          // å°è¯•é‡æ–°å¯åŠ¨å±å¹•æ•è·
          try {
            await this.screenCapture.startScreenCapture()
            // ç­‰å¾…Vueå“åº”æ€§æ›´æ–°
            await new Promise(resolve => setTimeout(resolve, 50))
            if (!this.screenCapture.getStreamingStatus()) {
              console.error('ğŸ“¸ å±å¹•æµé‡æ–°å¯åŠ¨å¤±è´¥')
              return
            }
            console.log('ğŸ“¸ å±å¹•æµé‡æ–°å¯åŠ¨æˆåŠŸ')
          } catch (restartError) {
            console.error('ğŸ“¸ é‡æ–°å¯åŠ¨å±å¹•æ•è·å¤±è´¥:', restartError)
            return
          }
        }

        const quality = this.config.screenshotConfig?.imageQuality ?? 0.8
        const base64Data = await this.screenCapture.captureFrame(quality)

        if (base64Data && base64Data.length > 0) {
          this.addScreenshot({ data: base64Data, timestamp: Date.now() })
        } else {
          console.warn('ğŸ“¸ æˆªå›¾å¤±è´¥ï¼šæ•°æ®ä¸ºç©º')
        }
      } catch (error) {
        console.warn('ğŸ“¸ æˆªå›¾å¤±è´¥:', error)

        // å¦‚æœæ˜¯æµè¢«å…³é—­çš„é”™è¯¯ï¼Œå°è¯•é‡æ–°å¯åŠ¨
        if (error instanceof Error && error.message.includes('not active')) {
          console.log('ğŸ“¸ æ£€æµ‹åˆ°æµå·²å…³é—­ï¼Œå°è¯•é‡æ–°å¯åŠ¨...')
          try {
            await this.screenCapture.startScreenCapture()
            console.log('ğŸ“¸ å±å¹•æ•è·å·²é‡æ–°å¯åŠ¨')
          } catch (restartError) {
            console.error('ğŸ“¸ é‡æ–°å¯åŠ¨å±å¹•æ•è·å¤±è´¥:', restartError)
          }
        }
      }
    }, interval)

    console.log(`ğŸ–¼ï¸ æˆªå›¾å®šæ—¶å™¨å·²å¯åŠ¨ï¼Œé—´éš”: ${interval}ms, æœ€å¤§æˆªå›¾æ•°: ${maxScreenshots}`)
  }

  private addScreenshot(screenshot: Screenshot): void {
    // æ·»åŠ æ–°æˆªå›¾åˆ°æ•°ç»„å¼€å¤´
    this.screenshots.unshift(screenshot)

    // é™åˆ¶æˆªå›¾æ•°é‡
    const maxScreenshots = this.config.screenshotConfig?.maxScreenshots ?? 1
    if (this.screenshots.length > maxScreenshots) {
      this.screenshots = this.screenshots.slice(0, maxScreenshots)
    }

    this.emit('screenshotTaken', screenshot)
    console.log(`ğŸ“¸ æˆªå›¾å·²æ·»åŠ ï¼Œå½“å‰æ•°é‡: ${this.screenshots.length}/${maxScreenshots}`)
  }

  private getLatestScreenshots(count?: number): Screenshot[] {
    const maxScreenshots = this.config.screenshotConfig?.maxScreenshots ?? 1
    const screenshotCount = count ?? maxScreenshots

    // è¿”å›æœ€æ–°çš„æˆªå›¾ï¼ˆæ•°ç»„å¼€å¤´æ˜¯æœ€æ–°çš„ï¼‰
    const result = this.screenshots.slice(0, screenshotCount)

    console.log(`ğŸ“¸ è·å–æœ€æ–°æˆªå›¾: è¯·æ±‚ ${screenshotCount} å¼ , å®é™…è¿”å› ${result.length} å¼ `)
    return result
  }

  // æ¸…ç©ºæˆªå›¾
  clearScreenshots(): void {
    this.screenshots = []
    this.emit('screenshotsCleared')
  }

  // éŸ³é¢‘æ•°æ®å¤„ç†
  private combineAudioChunks(): string {
    if (this.audioChunks.length === 0) {
      return ''
    }
    
    console.log('ğŸµ åˆå¹¶éŸ³é¢‘å—', {
      chunks: this.audioChunks.length,
      sampleRate: this.config.audioConfig?.sampleRate ?? 16000
    })
    
    try {
      // å°†æ‰€æœ‰base64å—è§£ç ä¸ºPCM16æ•°æ®
      const pcmBuffers: ArrayBuffer[] = []
      let totalBytes = 0
      
      for (const base64Chunk of this.audioChunks) {
        if (!base64Chunk || base64Chunk.trim() === '') continue
        
        try {
          const binaryString = atob(base64Chunk)
          const bytes = new Uint8Array(binaryString.length)
          for (let i = 0; i < binaryString.length; i++) {
            bytes[i] = binaryString.charCodeAt(i)
          }
          pcmBuffers.push(bytes.buffer)
          totalBytes += bytes.buffer.byteLength
        } catch (error) {
          console.warn('è§£ç éŸ³é¢‘å—å¤±è´¥:', error)
        }
      }
      
      if (totalBytes === 0) {
        console.warn('æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘æ•°æ®')
        return ''
      }
      
      // åˆå¹¶æ‰€æœ‰PCMæ•°æ®
      const mergedBuffer = new ArrayBuffer(totalBytes)
      const mergedView = new Uint8Array(mergedBuffer)
      let offset = 0
      
      for (const buffer of pcmBuffers) {
        mergedView.set(new Uint8Array(buffer), offset)
        offset += buffer.byteLength
      }
      
      // è½¬æ¢ä¸ºWAVæ ¼å¼
      const sampleRate = this.config.audioConfig?.sampleRate ?? 16000
      const wavBuffer = this.pcm16ToWavBuffer(mergedBuffer, sampleRate, 1)
      
      // è½¬æ¢ä¸ºbase64
      const base64 = this.bufferToBase64(wavBuffer)
      
      console.log('ğŸµ éŸ³é¢‘åˆå¹¶å®Œæˆ', {
        originalBytes: totalBytes,
        wavBytes: wavBuffer.byteLength,
        base64Length: base64.length
      })
      
      return base64
    } catch (error) {
      console.error('åˆå¹¶éŸ³é¢‘å—å¤±è´¥:', error)
      return ''
    }
  }
  
  // å°†PCM16æ•°æ®è½¬æ¢ä¸ºWAVæ ¼å¼
  private pcm16ToWavBuffer(pcmBuffer: ArrayBuffer, sampleRate: number, channelCount: number): ArrayBuffer {
    const channels = Math.max(1, channelCount || 1)
    const bytesPerSample = 2
    const blockAlign = channels * bytesPerSample
    const byteRate = sampleRate * blockAlign
    const dataLength = pcmBuffer.byteLength

    const buffer = new ArrayBuffer(44 + dataLength)
    const view = new DataView(buffer)
    let offset = 0

    const writeString = (value: string) => {
      for (let i = 0; i < value.length; i++) {
        view.setUint8(offset++, value.charCodeAt(i))
      }
    }

    const writeUint32 = (value: number) => {
      view.setUint32(offset, value, true)
      offset += 4
    }

    const writeUint16 = (value: number) => {
      view.setUint16(offset, value, true)
      offset += 2
    }

    // WAVæ–‡ä»¶å¤´
    writeString('RIFF')
    writeUint32(36 + dataLength)
    writeString('WAVE')
    writeString('fmt ')
    writeUint32(16)
    writeUint16(1) // PCM
    writeUint16(channels)
    writeUint32(sampleRate)
    writeUint32(byteRate)
    writeUint16(blockAlign)
    writeUint16(16) // bits per sample
    writeString('data')
    writeUint32(dataLength)

    // å¤åˆ¶PCMæ•°æ®
    const pcmView = new Uint8Array(pcmBuffer)
    new Uint8Array(buffer, 44).set(pcmView)

    return buffer
  }
  
  // å°†ArrayBufferè½¬æ¢ä¸ºbase64
  private bufferToBase64(buffer: ArrayBuffer): string {
    let binary = ''
    const bytes = new Uint8Array(buffer)

    for (let i = 0; i < bytes.byteLength; i++) {
      binary += String.fromCharCode(bytes[i])
    }

    return btoa(binary)
  }

  // é…ç½®æ›´æ–°
  updateConfig(newConfig: Partial<MultiModalServiceConfig>): void {
    if (newConfig.agentConfig) {
      // æ›´æ–°Agenté…ç½®
      if (newConfig.agentConfig.systemPrompt) {
        this.agent.updateSystemPrompt(newConfig.agentConfig.systemPrompt)
      }
      if (newConfig.agentConfig.llmConfig) {
        this.agent.updateLLMConfig(newConfig.agentConfig.llmConfig)
      }
      this.config.agentConfig = { ...this.config.agentConfig, ...newConfig.agentConfig }
    }

    if (newConfig.conversationConfig) {
      // æ›´æ–°å¯¹è¯é…ç½®
      this.config.conversationConfig = { ...this.config.conversationConfig, ...newConfig.conversationConfig }
      // æ›´æ–°Agentçš„é…ç½®
      const agentUpdates: any = {}
      if (newConfig.conversationConfig.sendHistoryImages !== undefined) {
        agentUpdates.sendHistoryImages = newConfig.conversationConfig.sendHistoryImages
      }
      if (newConfig.conversationConfig.sendHistoryAudio !== undefined) {
        agentUpdates.sendHistoryAudio = newConfig.conversationConfig.sendHistoryAudio
      }
      if (Object.keys(agentUpdates).length > 0) {
        this.agent.updateConfig(agentUpdates)
      }
    }

    if (newConfig.vadConfig) {
      this.config.vadConfig = { ...this.config.vadConfig, ...newConfig.vadConfig }
      this.vadDetector.updateConfig(newConfig.vadConfig)
    }

    if (newConfig.audioConfig) {
      this.config.audioConfig = { ...this.config.audioConfig, ...newConfig.audioConfig }
    }

    if (newConfig.screenshotConfig) {
      this.config.screenshotConfig = { ...this.config.screenshotConfig, ...newConfig.screenshotConfig }

      // å¦‚æœå±å¹•æ•è·æ­£åœ¨è¿è¡Œï¼Œé‡æ–°å¯åŠ¨æˆªå›¾å®šæ—¶å™¨ä»¥åº”ç”¨æ–°çš„é…ç½®
      if (this.status.isCapturing && this.captureTimer) {
        console.log('ğŸ“¸ æˆªå›¾é…ç½®å·²æ›´æ–°ï¼Œé‡æ–°å¯åŠ¨å®šæ—¶å™¨')
        clearInterval(this.captureTimer)
        this.captureTimer = null
        this.startScreenshotCapture()
      }
    }

    this.emit('configUpdated', this.config)
  }

  setToolsEnabled(enabled: boolean): void {
    this.toolsEnabled = enabled
    this.agent.setToolsEnabled(enabled)
  }

  // è®¾ç½®ä¼šè¯ä¿å­˜å›åˆæ•°
  setMaxHistoryRounds(rounds: number): void {
    // æ¯è½®åŒ…å«ä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯å’Œä¸€ä¸ªAIå›å¤ï¼Œæ‰€ä»¥æœ€å¤§å†å²å¤§å° = è½®æ•° * 2
    const maxHistorySize = Math.max(1, rounds) * 2
    this.agent.setMaxHistorySize(maxHistorySize)
    console.log('ğŸ“ MultiModalService maxHistoryRounds set to:', rounds, 'maxHistorySize:', maxHistorySize)
  }

  // è·å–ä¼šè¯ä¿å­˜å›åˆæ•°
  getMaxHistoryRounds(): number {
    // æœ€å¤§å†å²å¤§å° / 2 = è½®æ•°
    return Math.max(1, Math.floor(this.agent.getMaxHistorySize() / 2))
  }

  // åˆ›å»ºæ–‡æœ¬å›å¤ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰
  async createResponse(text: string): Promise<void> {
    if (!text || !text.trim()) {
      console.warn('ç©ºæ–‡æœ¬æ¶ˆæ¯ï¼Œè·³è¿‡å‘é€')
      return
    }

    try {
      console.log('ğŸ“¤ å‘é€æ–‡æœ¬æ¶ˆæ¯:', text)
      await this.agent.sendTextMessage(text.trim())
    } catch (error) {
      console.error('å‘é€æ–‡æœ¬æ¶ˆæ¯å¤±è´¥:', error)
      throw error
    }
  }

  // å‘é€å¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆæ–‡æœ¬ + å›¾ç‰‡ + è§†é¢‘ + éŸ³é¢‘ï¼‰
  async sendMultiModalMessage(options: {
    text: string
    images?: string[]
    videos?: string[]
    audios?: string[]
  }): Promise<void> {
    const { text, images, videos, audios } = options
    
    console.log('ğŸ“¤ MultiModalService.sendMultiModalMessage è°ƒç”¨:', {
      text: text.substring(0, 50),
      images: images?.length || 0,
      videos: videos?.length || 0,
      audios: audios?.length || 0
    })

    try {
      // å°†å›¾ç‰‡ã€è§†é¢‘ã€éŸ³é¢‘ä¸€å¹¶ä¼ é€’ç»™ Agentï¼ˆéŸ³é¢‘ä»¥base64å‘é€ï¼‰
      await this.agent.sendMultiModalMessage({
        text: text.trim(),
        images: images && images.length > 0 ? images : undefined,
        videos: videos && videos.length > 0 ? videos : undefined,
        audios: audios && audios.length > 0 ? audios : undefined
      })
    } catch (error) {
      console.error('å‘é€å¤šæ¨¡æ€æ¶ˆæ¯å¤±è´¥:', error)
      throw error
    }
  }

  // å‘é€å¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆæ–‡æœ¬ + å›¾ç‰‡ï¼‰
  async sendMultiModalTextMessage(text: string, images?: string[]): Promise<void> {
    if (!text || !text.trim()) {
      console.warn('ç©ºæ–‡æœ¬æ¶ˆæ¯ï¼Œè·³è¿‡å‘é€')
      return
    }

    try {
      console.log('ğŸ“¤ å‘é€å¤šæ¨¡æ€æ–‡æœ¬æ¶ˆæ¯:', { text, imageCount: images?.length || 0 })
      
      if (images && images.length > 0) {
        // å‘é€å¸¦å›¾ç‰‡çš„æ¶ˆæ¯
        await this.agent.sendMultiModalMessage({
          text: text.trim(),
          images: images,
          videos: undefined,
          audio: ''
        })
      } else {
        // å‘é€çº¯æ–‡æœ¬æ¶ˆæ¯
        await this.agent.sendTextMessage(text.trim())
      }
    } catch (error) {
      console.error('å‘é€å¤šæ¨¡æ€æ–‡æœ¬æ¶ˆæ¯å¤±è´¥:', error)
      throw error
    }
  }

  // è·å–çŠ¶æ€
  getStatus(): ServiceStatus {
    return { ...this.status }
  }

  getCurrentState(): ServiceState {
    return this.currentState
  }

  // å…¼å®¹æ€§æ–¹æ³• - ä¿æŒå‘åå…¼å®¹
  get state() {
    return this.status
  }

  // å·¥å…·æ–¹æ³•
  private isScreenshotPermissionDenied(error: unknown): boolean {
    if (!error) return false

    if (typeof DOMException !== 'undefined' && error instanceof DOMException) {
      return error.name === 'NotAllowedError' || error.name === 'NotReadableError'
    }

    if (error instanceof Error) {
      const message = error.message.toLowerCase()
      return message.includes('permission') || message.includes('denied')
    }

    return false
  }

  // é”€æ¯æœåŠ¡
  dispose(): void {
    console.log('ğŸ§¹ é”€æ¯MultiModalService')

    this.stopListening()
    this.stopScreenCapture()
    this.vadDetector.dispose()

    if (this.audioRecorder.isRecording()) {
      this.audioRecorder.stop()
    }

    if (this.audioStreamer) {
      this.audioStreamer.dispose()
    }

    if (this.captureTimer) {
      clearInterval(this.captureTimer)
    }

    this.removeAllListeners()
  }
}
