import { defineStore } from 'pinia'
import { ref, computed } from 'vue'

export interface ConversationMessage {
  id: string
  role: 'user' | 'assistant' | 'system'
  content: any
  timestamp: Date
  type: 'text' | 'audio' | 'image'
  transcription?: string
  audioData?: string
  imageData?: string
}

export const useConversationStore = defineStore('conversation', () => {
  // æ¶ˆæ¯åˆ—è¡¨
  const messages = ref<ConversationMessage[]>([])

  // å¤„ç†çŠ¶æ€
  const isProcessing = ref(false)
  const currentResponse = ref<string | null>(null)
  const currentTranscription = ref<string | null>(null)

  // éŸ³é¢‘æ•°æ®
  const currentAudioData = ref<string[]>([])
  const currentImageData = ref<string[]>([])

  // é”™è¯¯çŠ¶æ€
  const conversationError = ref<string | null>(null)

  // ç»Ÿè®¡ä¿¡æ¯
  const stats = ref({
    totalMessages: 0,
    totalTokens: 0,
    averageResponseTime: 0,
    lastResponseTime: 0,
    failedRequests: 0
  })

  // è®¡ç®—å±æ€§
  const sortedMessages = computed(() => {
    return [...messages.value].sort((a, b) => a.timestamp.getTime() - b.timestamp.getTime())
  })

  const userMessages = computed(() => {
    return sortedMessages.value.filter(msg => msg.role === 'user')
  })

  const assistantMessages = computed(() => {
    return sortedMessages.value.filter(msg => msg.role === 'assistant')
  })

  const lastMessage = computed(() => {
    return sortedMessages.value[sortedMessages.value.length - 1] || null
  })

  const lastUserMessage = computed(() => {
    return userMessages.value[userMessages.value.length - 1] || null
  })

  const lastAssistantMessage = computed(() => {
    return assistantMessages.value[assistantMessages.value.length - 1] || null
  })

  const hasMessages = computed(() => messages.value.length > 0)

  const isGeneratingResponse = computed(() => isProcessing.value && currentResponse.value !== null)

  const conversationStats = computed(() => ({
    totalMessages: stats.value.totalMessages,
    totalTokens: stats.value.totalTokens,
    averageResponseTime: stats.value.averageResponseTime,
    lastResponseTime: stats.value.lastResponseTime,
    failedRequests: stats.value.failedRequests,
    messageCount: messages.value.length
  }))

  // åŠ¨ä½œ
  const addMessage = (message: Omit<ConversationMessage, 'id' | 'timestamp'>) => {
    const newMessage: ConversationMessage = {
      ...message,
      id: `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      timestamp: new Date()
    }

    // ä½¿ç”¨æ•°ç»„é‡æ–°èµ‹å€¼çš„æ–¹å¼å¼ºåˆ¶è§¦å‘Vueå“åº”å¼æ›´æ–°
    messages.value = [...messages.value, newMessage]
    stats.value.totalMessages++

    console.log('ğŸ’¬ æ·»åŠ æ–°æ¶ˆæ¯:', {
      role: newMessage.role,
      type: newMessage.type,
      contentPreview: typeof newMessage.content === 'string' 
        ? newMessage.content.slice(0, 50) + (newMessage.content.length > 50 ? '...' : '')
        : 'éæ–‡æœ¬å†…å®¹',
      totalMessages: messages.value.length
    })

    return newMessage
  }

  const addUserMessage = (content: any, type: 'text' | 'audio' | 'image' = 'text', transcription?: string) => {
    return addMessage({
      role: 'user',
      content,
      type,
      transcription
    })
  }

  const addAssistantMessage = (content: any, type: 'text' | 'audio' | 'image' = 'text', transcription?: string) => {
    return addMessage({
      role: 'assistant',
      content,
      type,
      transcription
    })
  }

  const addSystemMessage = (content: any, type: 'text' | 'audio' | 'image' = 'text') => {
    return addMessage({
      role: 'system',
      content,
      type
    })
  }

  const addToolMessage = (
    content: any,
    type: 'text' | 'audio' | 'image' = 'text',
    toolCallId?: string
  ) => {
    // å·¥å…·æ¶ˆæ¯åº”è¯¥æ˜¾ç¤ºä¸ºç”¨æˆ·è§’è‰²ï¼Œä½†å†…å®¹æ ¼å¼åŒ–ä¸ºå·¥å…·å“åº”
    const formattedContent = typeof content === 'string' && content.startsWith('{') ? 
      (() => {
        try {
          const parsed = JSON.parse(content);
          return `ğŸ”§ å·¥å…·æ‰§è¡Œç»“æœ: ${JSON.stringify(parsed, null, 2)}`;
        } catch {
          return `ğŸ”§ å·¥å…·æ‰§è¡Œç»“æœ: ${content}`;
        }
      })() :
      `ğŸ”§ å·¥å…·æ‰§è¡Œç»“æœ: ${content}`;

    return addMessage({
      role: 'user',
      content: formattedContent,
      type
    })
  }

  const updateMessage = (messageId: string, updates: Partial<ConversationMessage>) => {
    const messageIndex = messages.value.findIndex(msg => msg.id === messageId)
    if (messageIndex !== -1) {
      messages.value[messageIndex] = {
        ...messages.value[messageIndex],
        ...updates
      }
    }
  }

  const removeMessage = (messageId: string) => {
    const messageIndex = messages.value.findIndex(msg => msg.id === messageId)
    if (messageIndex !== -1) {
      messages.value.splice(messageIndex, 1)
    }
  }

  const clearMessages = () => {
    messages.value = []
    currentResponse.value = null
    currentTranscription.value = null
    currentAudioData.value = []
    currentImageData.value = []
    conversationError.value = null
    stats.value.totalMessages = 0
    stats.value.totalTokens = 0
  }

  const startProcessing = () => {
    isProcessing.value = true
    currentResponse.value = null
    currentTranscription.value = null
    currentAudioData.value = []
    currentImageData.value = []
    conversationError.value = null
  }

  const stopProcessing = () => {
    isProcessing.value = false
  }

  const updateCurrentResponse = (response: string) => {
    currentResponse.value = response
  }

  const updateCurrentTranscription = (transcription: string) => {
    currentTranscription.value = transcription
  }

  const addCurrentAudioData = (audioData: string) => {
    currentAudioData.value.push(audioData)
  }

  const addCurrentImageData = (imageData: string) => {
    currentImageData.value.push(imageData)
  }

  const completeResponse = (responseTime?: number) => {
    console.log('ğŸ† å®Œæˆå“åº”å¤„ç†', {
      hasText: !!currentResponse.value,
      textLength: currentResponse.value?.length ?? 0,
      hasAudio: currentAudioData.value.length > 0,
      audioChunks: currentAudioData.value.length,
      hasImage: currentImageData.value.length > 0,
      imageChunks: currentImageData.value.length,
      hasTranscription: !!(currentTranscription.value?.trim())
    })
    
    // æ•´åˆæ‰€æœ‰å“åº”å†…å®¹åˆ°ä¸€æ¡æ¶ˆæ¯ä¸­
    const hasText = currentResponse.value && currentResponse.value.trim().length > 0
    const hasAudio = currentAudioData.value.length > 0
    const hasImage = currentImageData.value.length > 0
    const hasTranscription = currentTranscription.value && currentTranscription.value.trim().length > 0

    if (hasText || hasAudio || hasImage) {
      // åˆ›å»ºä¸€æ¡ç»¼åˆæ¶ˆæ¯ï¼ŒåŒ…å«æ‰€æœ‰ç±»å‹çš„å†…å®¹
      const content: any = {}
      
      if (hasText) {
        content.text = currentResponse.value
      }
      
      if (hasAudio) {
        content.audio = {
          audioChunks: currentAudioData.value,
          totalDuration: currentAudioData.value.length * 0.1 // å‡è®¾æ¯ä¸ªchunk 100ms
        }
      }
      
      if (hasImage) {
        content.images = {
          imageChunks: currentImageData.value
        }
      }

      // ç¡®å®šä¸»è¦ç±»å‹ï¼ˆä¼˜å…ˆçº§ï¼šæ–‡æœ¬ > éŸ³é¢‘ > å›¾åƒï¼‰
      const primaryType = hasText ? 'text' : hasAudio ? 'audio' : 'image'
      
      // å¯¹äºæ··åˆå†…å®¹ï¼Œä¼˜å…ˆæ˜¾ç¤ºæ–‡æœ¬ï¼Œå…¶ä»–ä½œä¸ºé™„åŠ å†…å®¹
      const displayContent = hasText ? currentResponse.value : 
                           hasAudio ? 'ğŸ”Š è¯­éŸ³å›å¤' + (hasText ? ': ' + currentResponse.value : '') :
                           hasImage ? 'ğŸ‡ºï¸ å›¾åƒå›å¤' : 
                           'ğŸ¤– AIå›å¤'
      
      console.log('ğŸ’¬ æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯', {
        primaryType,
        hasTranscription,
        displayContentPreview: displayContent?.slice(0, 50)
      })
      
      // addAssistantMessage(displayContent, primaryType, hasTranscription ? currentTranscription.value! : undefined)
      console.warn('âš ï¸ æ¶ˆæ¯æ·»åŠ å·²è¢«ç¦ç”¨ï¼Œç°åœ¨ç”± App.vue çš„ handleResponseCompleted è´Ÿè´£')
    } else {
      console.warn('âš ï¸ æ²¡æœ‰å†…å®¹éœ€è¦æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨')
    }

    // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    if (responseTime) {
      stats.value.lastResponseTime = responseTime
      if (stats.value.totalMessages > 1) {
        stats.value.averageResponseTime = (stats.value.averageResponseTime + responseTime) / 2
      } else {
        stats.value.averageResponseTime = responseTime
      }
    }

    // é‡ç½®å½“å‰å“åº”
    currentResponse.value = null
    currentTranscription.value = null
    currentAudioData.value = []
    currentImageData.value = []
    isProcessing.value = false
    
    console.log('ğŸ† å“åº”å¤„ç†å®Œæˆï¼ŒçŠ¶æ€å·²é‡ç½®')
  }

  const setConversationError = (error: string | null) => {
    conversationError.value = error
    if (error) {
      stats.value.failedRequests++
    }
  }

  const incrementTokenCount = (tokens: number) => {
    stats.value.totalTokens += tokens
  }

  const getMessagesByType = (type: 'text' | 'audio' | 'image') => {
    return sortedMessages.value.filter(msg => msg.type === type)
  }

  const getMessagesByRole = (role: 'user' | 'assistant' | 'system') => {
    return sortedMessages.value.filter(msg => msg.role === role)
  }

  const searchMessages = (query: string) => {
    const lowerQuery = query.toLowerCase()
    return sortedMessages.value.filter(msg => {
      if (typeof msg.content === 'string') {
        return msg.content.toLowerCase().includes(lowerQuery)
      }
      if (msg.transcription) {
        return msg.transcription.toLowerCase().includes(lowerQuery)
      }
      return false
    })
  }

  const exportConversation = () => {
    return {
      messages: sortedMessages.value.map(msg => ({
        id: msg.id,
        role: msg.role,
        content: msg.content,
        timestamp: msg.timestamp.toISOString(),
        type: msg.type,
        transcription: msg.transcription
      })),
      stats: conversationStats.value,
      exportedAt: new Date().toISOString()
    }
  }

  const reset = () => {
    clearMessages()
    stats.value = {
      totalMessages: 0,
      totalTokens: 0,
      averageResponseTime: 0,
      lastResponseTime: 0,
      failedRequests: 0
    }
  }

  return {
    // çŠ¶æ€
    messages,
    isProcessing,
    currentResponse,
    currentTranscription,
    currentAudioData,
    currentImageData,
    conversationError,
    stats,

    // è®¡ç®—å±æ€§
    sortedMessages,
    userMessages,
    assistantMessages,
    lastMessage,
    lastUserMessage,
    lastAssistantMessage,
    hasMessages,
    isGeneratingResponse,
    conversationStats,

    // åŠ¨ä½œ
    addMessage,
    addUserMessage,
    addAssistantMessage,
    addSystemMessage,
    addToolMessage,
    updateMessage,
    removeMessage,
    clearMessages,
    startProcessing,
    stopProcessing,
    updateCurrentResponse,
    updateCurrentTranscription,
    addCurrentAudioData,
    addCurrentImageData,
    completeResponse,
    setConversationError,
    incrementTokenCount,
    getMessagesByType,
    getMessagesByRole,
    searchMessages,
    exportConversation,
    reset
  }
})
